{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-db663ab13f89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix,plot_confusion_matrix\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical  \n",
    "import tensorflow.keras.utils as util\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'splitfolders'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e7daf592ca1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msplitfolders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'splitfolders'"
     ]
    }
   ],
   "source": [
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_of_geometric(data):\n",
    "    F_lower=[[],[]]\n",
    "    F=[]\n",
    "    d=[]\n",
    "    f=[]\n",
    "\n",
    "    ox=np.array([1,0,0]).reshape(-1,1)\n",
    "    oy=np.array([0,1,0]).reshape(-1,1)\n",
    "    oz=np.array([0,0,1]).reshape(-1,1)\n",
    "\n",
    "    for N in range(1, (len(data)//20)+1):\n",
    "      F_lower=[[],[]]\n",
    "      for i in range((N-1)*20, N*20):\n",
    "        for j in range(i+1, N*20):\n",
    "          (xi, yi, zi)=data[i]\n",
    "          (xj, yj, zj)=data[j]\n",
    "          ji=np.sqrt((yj-yi)**2+(zj-zi)**2+(xj-xi)**2)\n",
    "\n",
    "          d.append(np.sqrt((yj-yi)**2+(zj-zi)**2))\n",
    "          d.append(np.sqrt((xj-xi)**2+(zj-zi)**2))\n",
    "          d.append(np.sqrt((xj-xi)**2+(yj-yi)**2))\n",
    "          F_lower[0].append(d)\n",
    "\n",
    "          if ji!=0.0:\n",
    "            t1=np.arccos(np.clip((np.dot(np.array(d), oy)//ji), -1.0, 1.0))\n",
    "            f.append(t1[0])\n",
    "            t2=np.arccos(np.clip((np.dot(np.array(d), oz)//ji), -1.0, 1.0))\n",
    "            f.append(t2[0])\n",
    "            t3=np.arccos(np.clip((np.dot(np.array(d), ox)//ji), -1.0, 1.0))\n",
    "            f.append(t3[0])\n",
    "            F_lower[1].append(f)\n",
    "          else:\n",
    "            f.append(0.0)\n",
    "            f.append(0.0)\n",
    "            f.append(0.0)\n",
    "            F_lower[1].append(f)\n",
    "\n",
    "          d=[]\n",
    "          f=[]\n",
    "      F.append(F_lower)\n",
    "      \n",
    "    F_means=[]\n",
    "    F_mean=[[], []]\n",
    "    \n",
    "    m=[[],[]]\n",
    "    tem=np.zeros((190, 3)).tolist()\n",
    "    m[0]=tem\n",
    "    m[1]=tem\n",
    "\n",
    "    count=0\n",
    "    k=0\n",
    "    while k<len(F):\n",
    "        if count==30:\n",
    "            k=k-24\n",
    "            count=0\n",
    "            m=(np.array(m)/30).tolist()\n",
    "            F_mean[0]=m[0]\n",
    "            F_mean[1]=m[1]\n",
    "            \n",
    "            F_means.append(F_mean)\n",
    "            \n",
    "            \n",
    "            F_mean=[[], []]\n",
    "            \n",
    "            m=[[],[]]\n",
    "            tem=np.zeros((190, 3)).tolist()\n",
    "            m[0]=tem\n",
    "            m[1]=tem\n",
    "            \n",
    "        for j in range(0, 190): \n",
    "          m[0][j]=(np.array(m[0][j])+np.array(F[k][0][j])).tolist()\n",
    "          m[1][j]=np.array(m[1][j])+np.array(F[k][1][j]).tolist()\n",
    "        \n",
    "        \n",
    "        if k==len(F)-1 and count!=30 and count!=0:\n",
    "            t=k-(k//30)*30\n",
    "            if t!=0:\n",
    "                m=(np.array(m)/t).tolist()\n",
    "                F_mean[0]=m[0]\n",
    "                F_mean[1]=m[1]\n",
    "                \n",
    "                F_means.append(F_mean)\n",
    "                \n",
    "        count+=1\n",
    "        k+=1\n",
    "\n",
    "    return F_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/content/drive/My Drive/GaitSequences1/test\"\n",
    "subfolders = [ f.path for f in os.scandir(path) if f.is_dir() ]\n",
    "\n",
    "data_per_sequence=[]\n",
    "test_ds=[[],[]]\n",
    "        \n",
    "for directory in subfolders:\n",
    "    label=int(os.path.basename(directory).lstrip('Person'))\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f):\n",
    "            if f.endswith(\".txt\"):\n",
    "                data_per_sequence=[]\n",
    "                with open(f, 'r') as fl:\n",
    "                    var=fl.read()\n",
    "                    for line in var.splitlines():\n",
    "                        aList = list(ast.literal_eval(line))\n",
    "                        data_per_sequence.append(aList)\n",
    "                    f_means=mean_of_geometric(data_per_sequence)\n",
    "                    for i in range(0, len(f_means)):\n",
    "                        test_ds[0].append(f_means[i])\n",
    "                        test_ds[1].append((label-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_ds[0]))\n",
    "print(len(test_ds[1]))\n",
    "print(np.array(test_ds[0]).shape)\n",
    "print(np.array(test_ds[1]).shape)\n",
    "print(test_ds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_data, train_label = shuffle(train_ds[0], train_ds[1])\n",
    "\n",
    "nsamples, nx, ny, nz = np.array(train_data).shape\n",
    "train_dataset = np.array(train_data).reshape((nsamples,nx*ny*nz))\n",
    "nsamples, nx, ny, nz = np.array(test_ds[0]).shape\n",
    "test_dataset = np.array(test_ds[0]).reshape((nsamples,nx*ny*nz))\n",
    "\n",
    "print(train_dataset.shape)\n",
    "print(np.array(train_ds[1]).shape)\n",
    "print(test_dataset.shape)\n",
    "print(np.array(test_ds[1]).shape)\n",
    "\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(C=8.0, random_state=1, kernel='linear')\n",
    "clf.fit(train_dataset, train_label)\n",
    "y_predict = clf.predict(test_dataset)\n",
    "print(\"SVM Accuracy: %.3f\" %metrics.accuracy_score(test_ds[1], y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./../savedModels/model.joblib']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model, './../savedModels/model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b302cdd1e032ee910f5c889c3360c28564c92ad4f326fc3102e39fbe47faee66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
